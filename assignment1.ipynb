{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d090de-688f-4deb-bef9-6296f9e478b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenbo\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a233910-60d7-41b8-b90e-c555af5c8c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda is available.\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"cuda is not available.\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "352bd6ee-9f33-4ccf-acf3-2b26e768ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"list some project ideas for beginner, intermediate, and advanced users for a large language model class.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf94a84-19be-4293-a598-9bac1f139ffb",
   "metadata": {},
   "source": [
    "## Model: Meta-llama/Llama-3.2-1B-Instruct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d98104-fc50-456f-81cf-a34772cb810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenbo\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device,\n",
    "    use_auth_token=True\n",
    ")\n",
    "\n",
    "generation_pipeline = pipeline(task=\"text-generation\",\n",
    "                               model=model,\n",
    "                               tokenizer=tokenizer\n",
    "                              )\n",
    "\n",
    "output = generation_pipeline(prompt, max_new_tokens=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdbcdeae-caa0-445d-b921-9d5797508294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list some project ideas for beginner, intermediate, and advanced users for a large language model class. Assign a difficulty level (DL) for each project and provide a brief description of the project and its requirements.\n",
      "\n",
      "**Beginner Projects**\n",
      "\n",
      "1. **Text Summarization**: Ask students to write a short summary of a given text (e.g., a news article or a short story). Students can use a specific dataset (e.g., a news article from a particular source) or create their own dataset. (DL: 1)\n",
      "2. **Sentiment Analysis**: Ask students to analyze the sentiment of a given text (e.g., a review or a comment). Students can use a specific dataset (e.g., a movie review dataset) or create their own dataset. (DL: 1)\n",
      "3. **Language Translation**: Ask students to translate a given text from one language to another (e.g., from English to Spanish). Students can use a specific dataset (e.g., a language translation dataset) or create their own dataset. (DL: 2)\n",
      "4. **Chatbot**: Ask students to create a simple chatbot that responds to basic user queries (e.g., \"What's the weather like today?\"). Students can use a specific dataset (e.g., a weather API) or create their own dataset. (DL: 2)\n",
      "5. **Text Classification**: Ask students to classify a given text into a specific category (e.g., spam vs. non-spam emails). Students can use a specific dataset (e.g., a spam email dataset) or create their own dataset. (DL: 2)\n",
      "\n",
      "**Intermediate Projects**\n",
      "\n",
      "1. **Named Entity Recognition (NER)**: Ask students to identify and extract specific entities (e.g., names, locations, organizations) from a given text. Students can use a specific dataset (e.g., a named entity recognition dataset) or create their own dataset. (DL: 3)\n",
      "2. **Text Classification with Sentiment Analysis**: Ask students to classify a given text into a specific category (e.g., spam vs. non-spam emails) and also analyze the sentiment of the text. Students can use a specific dataset (e.g., a spam email dataset) or create their own dataset. (DL: 3)\n",
      "3. **Language Modeling**: Ask students to train a language model on a given text dataset and then use the model to generate text (e.g., a short story or a paragraph). Students can use a specific dataset (e.g., a language modeling dataset) or create their own dataset. (DL: 3)\n",
      "4. **Question Answering**: Ask students to develop a question answering system that can answer a given question based on a given text. Students can use a specific dataset (e.g., a question answering dataset) or create their own dataset. (DL: 3)\n",
      "5. **Text Summarization with NER**: Ask students to combine text summarization and named entity recognition to create a system that can summarize a text while also extracting entities. Students can use a specific dataset (e.g., a text summarization dataset) or create their own dataset. (DL: 3)\n",
      "\n",
      "**Advanced Projects**\n",
      "\n",
      "1. **Multilingual Text Classification**: Ask students to develop a system that can classify text into multiple languages and also analyze the sentiment of the text. Students can use a specific dataset (e.g., a multilingual text classification dataset) or create their own dataset. (DL: 4)\n",
      "2. **Chatbot with Dialogue Management**: Ask students to develop a chatbot that can engage in a conversation with a user and also manage the conversation (e.g., respond to follow-up questions). Students can use a specific dataset (e.g., a dialogue management dataset) or create their own dataset. (DL: 4)\n",
      "3. **Text Generation with Style Transfer**: Ask students to develop a system that can generate text based on a given style (e.g., a specific genre or tone). Students can use a specific dataset (e.g., a text generation dataset) or create their own dataset. (DL: 4)\n",
      "4. **Sentiment Analysis with Transfer Learning**: Ask students to develop a system that can use pre-trained language models and fine-tune them for sentiment analysis. Students can use a specific dataset (e.g., a sentiment analysis dataset) or create their own dataset. (DL: 4)\n",
      "5. **Dialogue Systems with Reasoning**: Ask students to develop a system that can engage in a conversation and also reason about the conversation (e.g., make inferences or draw conclusions). Students can use a specific dataset (e.g., a dialogue reasoning dataset) or create their own dataset. (DL: 4)\n",
      "\n",
      "Note: The difficulty level (DL) is subjective and may vary depending on the student's background and experience. The requirements and datasets may also need to be adjusted based on the specific needs of the project.\n"
     ]
    }
   ],
   "source": [
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ee4ff-927c-47bc-a6a6-65fefd60f5b4",
   "metadata": {},
   "source": [
    "## Model: Mistral-7B-Instruct-v0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26376543-2fee-402c-af2f-93796cd966d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfbcf78f03e48adbbe1802010977f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenbo\\anaconda3\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "C:\\Users\\kenbo\\anaconda3\\Lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=device, torch_dtype=torch.bfloat16, load_in_8bit=True)\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate text\n",
    "outputs = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=1800,  # Adjust length as needed\n",
    "    num_beams=5,     # Controls diversity\n",
    "    temperature=0.7  # Adjust creativity\n",
    ")\n",
    "\n",
    "# Decode and print the output\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e308fe-c18f-47ad-95be-842f4df8a0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list some project ideas for beginner, intermediate, and advanced users for a large language model class.\n",
      "\n",
      "For a large language model class, here are some project ideas categorized by beginner, intermediate, and advanced users:\n",
      "\n",
      "Beginner:\n",
      "1. Sentiment Analysis: Develop a simple sentiment analysis tool that classifies text as positive, negative, or neutral. This can be applied to social media posts, product reviews, or news articles.\n",
      "2. Spell Checker: Create a spell checker that suggests corrections for misspelled words in a given text.\n",
      "3. Question Answering System: Develop a question answering system that can answer simple questions based on a given context or a knowledge base.\n",
      "4. Text Summarization: Create a text summarization tool that can condense long articles or documents into shorter summaries.\n",
      "5. Text Classification: Develop a text classifier that can categorize text into predefined categories, such as news, sports, or entertainment.\n",
      "\n",
      "Intermediate:\n",
      "1. Named Entity Recognition: Build a named entity recognition system that can identify and classify named entities (e.g., people, organizations, locations) in a given text.\n",
      "2. Machine Translation: Develop a machine translation system that can translate text from one language to another.\n",
      "3. Dialogue System: Create a dialogue system that can carry on a conversation with a user, answering questions and providing information.\n",
      "4. Text Generation: Develop a text generation model that can generate coherent and grammatically correct sentences or paragraphs.\n",
      "5. Topic Modeling: Build a topic modeling system that can discover hidden topics in a large corpus of text data.\n",
      "\n",
      "Advanced:\n",
      "1. Information Extraction: Develop an information extraction system that can automatically extract structured information (e.g., names, addresses, phone numbers) from unstructured text data.\n",
      "2. Semantic Role Labeling: Build a semantic role labeling system that can identify the roles that entities play in a sentence (e.g., agent, patient, instrument).\n",
      "3. Textual Entailment: Develop a textual entailment system that can determine whether one text logically entails another.\n",
      "4. Textual Inference: Build a textual inference system that can make logical inferences based on a given text.\n",
      "5. Reading Comprehension: Develop a reading comprehension system that can answer complex questions based on a given text passage.\n"
     ]
    }
   ],
   "source": [
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc00310-1e2b-4473-8e65-c3047b0b3451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
